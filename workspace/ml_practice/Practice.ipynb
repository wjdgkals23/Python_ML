{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '어항 속에 갇힌 고기들보다 어쩌면 내가 좀 더 멍청할지 몰라'\n",
    "\n",
    "sample = '어항 속에 갇힌 고기들보다 어쩌면 내가 좀 더 멍청할지 몰라 너가 먹이처럼 던진 문자 몇 통과 너의 부재중 전화는 날 헷갈리게 하지 너의 미모와 옷 입는 스타일로 미루어 보았을 때 너의 어장의 크기는 수족관의 크기 단지 너 하나 때문에 경쟁은 무척 험하고도 아득해 난 너의 생선이 아닌 남자친구가 되고싶어 허나 너에겐 늘 누군가가 옆에 있어 이럴 때일수록 내 이미지를 위해선 그저 쏘 쿨한 척 하는 게 최선 임을 알기에 좋은 시간을 가지라고 나는 말했고, 그날 밤 업데이트 된 너의 페북의 담벼락엔 여전히 물고기들이 하악 하악 당연히 나도 그 중 하나 하루 종일 너란 바닷속을 항해하는 나는 아쿠아맨 헤엄 헤엄 헤엄 네 마음 속 깊은 곳에서 헤엄쳐 너의 어장은 너무 캄캄해 헤엄 헤엄 헤엄 손에 꼽을 정도로 아주 가끔씩 엉뚱한 시간에 넌 내가 어딘지 묻지 어디긴 니 마음이지 라는 본심을 속이며 차분하게 말했지 지금 집 심상치 않은 징조, 심장은 보다 신속 혹시 모를 급만남이 꿈처럼 이루어 질 수도 있을 것 같은 느낌이 들어 지금 너의 위치가 어디든 너가 있는 곳으로 갈게 통장 잔고는 가까스로 위기모면 입을 옷도 이미 정했어 목걸이는 크롬하츠 그러나 너는 말헀지, 그런 거 아니고 더이상 전화하지 마 제발. 안 돼~~ 하루 종일 너란 바닷속을 항해하는 나는 아쿠아맨 헤엄 헤엄 헤엄 네 마음 속 깊은 곳에서 헤엄쳐 너의 어장은 너무 캄캄해 헤엄 헤엄 헤엄 내 가슴은 회처럼 조각이 났지 너는 내 상처난 심장에 신경도 쓰지 않지. 넌 딱 잘라 말했지 손톱깎이 같이 얘야 난 네 심장에 신경을 쓰지 않아 하루 종일 너란 바닷속을 항해하는 나는 아쿠아맨 헤엄 헤엄 헤엄 네 마음 속 깊은 곳에서 헤엄쳐 너의 어장은 너무 캄캄해 헤엄 헤엄 헤엄 너의 얼굴과 몸이 영원할까'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['어항', '속', '고기', '어쩌면', '내', '좀', '더']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize\n",
    "from konlpy.tag import *\n",
    "\n",
    "twitter = Okt()\n",
    "kkma = Kkma()\n",
    "# komoran = Komora()\n",
    "\n",
    "kkma.nouns(text)\n",
    "\n",
    "twitter.nouns(text)\n",
    "\n",
    "# komoran.nouns(text) # 명사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding - Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "token = twitter.nouns(sample)\n",
    "token\n",
    "\n",
    "CB_Model = Word2Vec(token, sg=0, window=5, size=10, min_count=1) \n",
    "# sg = 0 cbow 방식 # 히든레이어의 차수 결정 size = 10 # min_count는 2개 밑으로 나온 놈은 빼\n",
    "\n",
    "CB_Model.wv.index2word\n",
    "CB_Model.wv.vectors \n",
    "## 각항목별 vector\n",
    "\n",
    "result = dict(zip(CB_Model.wv.index2word, CB_Model.wv.vectors))\n",
    "\n",
    "result\n",
    "\n",
    "SG_Model = Word2Vec(token, sg=1, window=5, size=5, min_count=2)\n",
    "\n",
    "result2 = dict(zip(SG_Model.wv.index2word, SG_Model.wv.vectors))\n",
    "\n",
    "result2\n",
    "\n",
    "# Embedding - FastText\n",
    "from gensim.models import FastText\n",
    "\n",
    "FT_Model = FastText(token, sg=1, window=5, size=5, min_count=2, min_n=2, max_n=4)\n",
    "\n",
    "FT_Model.wv.vectors\n",
    "\n",
    "sample = '어항 속에 갇힌 고기들보다 어쩌면 내가 좀 더 멍청할지 몰라 너가 먹이처럼 던진 문자 몇 통과 너의 부재중 전화는 날 헷갈리게 하지 너의 미모와 옷 입는 스타일로 미루어 보았을 때 너의 어장의 크기는 수족관의 크기 단지 너 하나 때문에 경쟁은 무척 험하고도 아득해 난 너의 생선이 아닌 남자친구가 되고싶어 허나 너에겐 늘 누군가가 옆에 있어 이럴 때일수록 내 이미지를 위해선 그저 쏘 쿨한 척 하는 게 최선 임을 알기에 좋은 시간을 가지라고 나는 말했고, 그날 밤 업데이트 된 너의 페북의 담벼락엔 여전히 물고기들이 하악 하악 당연히 나도 그 중 하나 하루 종일 너란 바닷속을 항해하는 나는 아쿠아맨 헤엄 헤엄 헤엄 네 마음 속 깊은 곳에서 헤엄쳐 너의 어장은 너무 캄캄해 헤엄 헤엄 헤엄 손에 꼽을 정도로 아주 가끔씩 엉뚱한 시간에 넌 내가 어딘지 묻지 어디긴 니 마음이지 라는 본심을 속이며 차분하게 말했지 지금 집 심상치 않은 징조, 심장은 보다 신속 혹시 모를 급만남이 꿈처럼 이루어 질 수도 있을 것 같은 느낌이 들어 지금 너의 위치가 어디든 너가 있는 곳으로 갈게 통장 잔고는 가까스로 위기모면 입을 옷도 이미 정했어 목걸이는 크롬하츠 그러나 너는 말헀지, 그런 거 아니고 더이상 전화하지 마 제발. 안 돼~~ 하루 종일 너란 바닷속을 항해하는 나는 아쿠아맨 헤엄 헤엄 헤엄 네 마음 속 깊은 곳에서 헤엄쳐 너의 어장은 너무 캄캄해 헤엄 헤엄 헤엄 내 가슴은 회처럼 조각이 났지 너는 내 상처난 심장에 신경도 쓰지 않지. 넌 딱 잘라 말했지 손톱깎이 같이 얘야 난 네 심장에 신경을 쓰지 않아 하루 종일 너란 바닷속을 항해하는 나는 아쿠아맨 헤엄 헤엄 헤엄 네 마음 속 깊은 곳에서 헤엄쳐 너의 어장은 너무 캄캄해 헤엄 헤엄 헤엄 너의 얼굴과 몸이 영원할까'\n",
    "\n",
    "# Tokenize\n",
    "from konlpy.tag import *\n",
    "\n",
    "twitter = Okt()\n",
    "kkma = Kkma()\n",
    "komoran = Komora()\n",
    "\n",
    "kkma.nouns(text)\n",
    "\n",
    "twitter.nouns(text)\n",
    "\n",
    "komoran.nouns(text) # 명사\n",
    "komoran.morphs(text) # 형태소\n",
    "\n",
    "# Embedding - Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "token = twitter.nouns(sample)\n",
    "token\n",
    "\n",
    "CB_Model = Word2Vec(token, sg=0, window=5, size=10, min_count=1) \n",
    "# sg = 0 cbow 방식 # 히든레이어의 차수 결정 size = 10 # min_count는 2개 밑으로 나온 놈은 빼\n",
    "\n",
    "CB_Model.wv.index2word\n",
    "CB_Model.wv.vectors \n",
    "## 각항목별 vector\n",
    "\n",
    "result = dict(zip(CB_Model.wv.index2word, CB_Model.wv.vectors))\n",
    "\n",
    "result\n",
    "\n",
    "SG_Model = Word2Vec(token, sg=1, window=5, size=5, min_count=2)\n",
    "\n",
    "result2 = dict(zip(SG_Model.wv.index2word, SG_Model.wv.vectors))\n",
    "\n",
    "result2\n",
    "\n",
    "# Embedding - FastText\n",
    "from gensim.models import FastText\n",
    "\n",
    "FT_Model = FastText(token, sg=1, window=5, size=5, min_count=2, min_n=2, max_n=4)\n",
    "\n",
    "FT_Model.wv.vectors\n",
    "\n",
    "FT_Model.wv.most_similar('나')\n",
    "\n",
    "# 과제\n",
    "csv 파일 내, Text를 Embedding 한 후 비지도학습을 이용하여 군집을 나눠주세요.\n",
    "나누어진 군집과 Keyword의 군집을 비교해보세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
