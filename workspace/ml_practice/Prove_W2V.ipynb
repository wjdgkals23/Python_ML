{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "corpus = [['이잉걸', '학생', '은', '회장'],['김수지', '학생', '은', '부회장']]\n",
    "words = ['이잉걸', '학생', '은', '회장', '김수지', '부회장'] # Corpus 중복제거\n",
    "\n",
    "# One-Hot Encoding\n",
    "이잉걸 = np.array([1, 0, 0, 0, 0, 0])\n",
    "학생 = np.array([0, 1, 0, 0, 0, 0])\n",
    "은 = np.array([0, 0, 1, 0, 0, 0])\n",
    "회장 = np.array([0, 0, 0, 1, 0, 0])\n",
    "김수지 = np.array([0, 0, 0, 0, 1, 0])\n",
    "부회장 = np.array([0, 0, 0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window Size = 2\n",
    "data = np.array( \n",
    "    [[이잉걸, 학생],[이잉걸, 은],[학생, 이잉걸],[학생, 은],[학생, 회장],[은, 이잉걸],[은, 학생],[은, 회장],[회장, 학생],[회장, 은],\n",
    "     [김수지, 학생],[김수지, 은],[학생, 김수지],[학생, 은],[학생, 부회장],[은, 김수지],[은, 학생],[은, 부회장],[부회장, 학생],[부회장, 은]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[0][0] # Input\n",
    "y = data[0][1] # Target\n",
    "\n",
    "for data2 in data[1:]:\n",
    "\tx = np.vstack([x, data2[0]])\n",
    "\ty = np.vstack([y, data2[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function:  118.36243\n",
      "Loss Function:  36.951813\n",
      "Loss Function:  27.851482\n",
      "Loss Function:  25.987381\n",
      "Loss Function:  25.387337\n",
      "Loss Function:  25.08928\n",
      "Loss Function:  24.909557\n",
      "Loss Function:  24.790224\n",
      "Loss Function:  24.705864\n",
      "Loss Function:  24.643452\n",
      "Loss Function:  24.595638\n",
      "Loss Function:  24.55798\n",
      "Loss Function:  24.52764\n",
      "Loss Function:  24.502739\n",
      "Loss Function:  24.481976\n",
      "Loss Function:  24.464422\n",
      "Loss Function:  24.449413\n",
      "Loss Function:  24.436447\n",
      "Loss Function:  24.42514\n",
      "Loss Function:  24.415209\n",
      "Loss Function:  24.406418\n",
      "Loss Function:  24.39859\n",
      "Loss Function:  24.391575\n",
      "Loss Function:  24.385262\n",
      "Loss Function:  24.379549\n",
      "Loss Function:  24.374357\n",
      "Loss Function:  24.369621\n",
      "Loss Function:  24.365284\n",
      "Loss Function:  24.361298\n",
      "Loss Function:  24.357624\n",
      "Loss Function:  24.354229\n",
      "Loss Function:  24.351082\n",
      "Loss Function:  24.348154\n",
      "Loss Function:  24.345432\n",
      "Loss Function:  24.342886\n",
      "Loss Function:  24.340506\n",
      "Loss Function:  24.338276\n",
      "Loss Function:  24.33618\n",
      "Loss Function:  24.33421\n",
      "Loss Function:  24.332352\n",
      "Loss Function:  24.330597\n",
      "Loss Function:  24.32894\n",
      "Loss Function:  24.327368\n",
      "Loss Function:  24.32588\n",
      "Loss Function:  24.324467\n",
      "Loss Function:  24.323128\n",
      "Loss Function:  24.321848\n",
      "Loss Function:  24.320633\n",
      "Loss Function:  24.319475\n",
      "Loss Function:  24.318367\n",
      "Loss Function:  24.31731\n",
      "Loss Function:  24.3163\n",
      "Loss Function:  24.315329\n",
      "Loss Function:  24.314402\n",
      "Loss Function:  24.313515\n",
      "Loss Function:  24.312658\n",
      "Loss Function:  24.31184\n",
      "Loss Function:  24.311054\n",
      "Loss Function:  24.310295\n",
      "Loss Function:  24.309565\n",
      "Loss Function:  24.308863\n",
      "Loss Function:  24.308186\n",
      "Loss Function:  24.307535\n",
      "Loss Function:  24.306906\n",
      "Loss Function:  24.306295\n",
      "Loss Function:  24.30571\n",
      "Loss Function:  24.305141\n",
      "Loss Function:  24.304592\n",
      "Loss Function:  24.304062\n",
      "Loss Function:  24.303547\n",
      "Loss Function:  24.30305\n",
      "Loss Function:  24.302567\n",
      "Loss Function:  24.302101\n",
      "Loss Function:  24.301647\n",
      "Loss Function:  24.301207\n",
      "Loss Function:  24.300777\n",
      "Loss Function:  24.300365\n",
      "Loss Function:  24.299961\n",
      "Loss Function:  24.299568\n",
      "Loss Function:  24.29919\n",
      "Loss Function:  24.298817\n",
      "Loss Function:  24.29846\n",
      "Loss Function:  24.298107\n",
      "Loss Function:  24.297766\n",
      "Loss Function:  24.297436\n",
      "Loss Function:  24.297112\n",
      "Loss Function:  24.296797\n",
      "Loss Function:  24.296488\n",
      "Loss Function:  24.296188\n",
      "Loss Function:  24.295895\n",
      "Loss Function:  24.295612\n",
      "Loss Function:  24.29533\n",
      "Loss Function:  24.29506\n",
      "Loss Function:  24.294796\n",
      "Loss Function:  24.294537\n",
      "Loss Function:  24.294283\n",
      "Loss Function:  24.294035\n",
      "Loss Function:  24.293793\n",
      "Loss Function:  24.293556\n",
      "Loss Function:  24.293325\n"
     ]
    }
   ],
   "source": [
    "# Network\n",
    "n_words = len(words)\n",
    "size = 10\n",
    "\n",
    "X = tf.placeholder(shape=[None, n_words], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, n_words], dtype = tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([n_words, size], dtype = tf.float32))\n",
    "b1 = tf.Variable(tf.random_normal([size], dtype = tf.float32))\n",
    "hidden = tf.add(tf.matmul(X, w1), b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([size, n_words], dtype = tf.float32))\n",
    "b2 = tf.Variable(tf.random_normal([n_words], dtype = tf.float32))\n",
    "output = tf.add(tf.matmul(hidden, w2), b2)\n",
    "\n",
    "network_output = tf.nn.softmax(output)\n",
    "network_cost = tf.reduce_mean(tf.reduce_sum(-tf.log(network_output) * y))\n",
    "network_optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
    "network_training = network_optimizer.minimize(network_cost)\n",
    "\n",
    "network_session = tf.Session()\n",
    "variables_initializer = tf.global_variables_initializer()\n",
    "network_session.run(variables_initializer)\n",
    "\n",
    "for i in range(10000):\n",
    "\tnetwork_session.run(network_training, feed_dict = {X: x, Y: y})\n",
    "\tif i % 100 == 0:\n",
    "\t\tprint(\"Loss Function: \", network_session.run(network_cost, feed_dict={X: x, Y:y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9413003 ,  1.8734531 , -0.9507375 ,  0.3802702 , -3.1289344 ,\n",
       "         0.20544308,  1.2632269 , -0.1426189 ,  0.6573719 ,  1.3963253 ],\n",
       "       [ 0.22291288,  0.29848224, -1.6472098 ,  0.3392419 , -1.988097  ,\n",
       "        -1.1445596 , -1.7179128 ,  0.72005886,  2.7951117 ,  0.21058607],\n",
       "       [ 1.3530395 ,  1.152476  , -0.00490719,  1.1032438 , -2.1967862 ,\n",
       "        -2.1037016 , -0.16869897,  1.099882  ,  0.39877808, -0.33955395],\n",
       "       [ 0.55242383,  1.8319519 , -1.798766  ,  1.9305265 , -2.5245993 ,\n",
       "        -0.5049012 ,  0.61437875,  1.3248427 ,  1.2709328 ,  2.480298  ],\n",
       "       [ 0.21701005,  2.8249235 ,  0.04478335,  0.61945814, -3.5394843 ,\n",
       "         0.83527565,  0.592495  ,  0.13162851,  1.5641346 ,  2.2889524 ],\n",
       "       [ 1.5856258 ,  1.3863528 , -0.66121197,  0.71799254, -1.1571159 ,\n",
       "         0.47218645,  3.350997  ,  1.9592443 ,  1.5252193 ,  0.6469809 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_result = network_session.run(w1 + b1)\n",
    "w2v_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'김수지': array([ 0.21701005,  2.8249235 ,  0.04478335,  0.61945814, -3.5394843 ,\n",
       "         0.83527565,  0.592495  ,  0.13162851,  1.5641346 ,  2.2889524 ],\n",
       "       dtype=float32),\n",
       " '부회장': array([ 1.5856258 ,  1.3863528 , -0.66121197,  0.71799254, -1.1571159 ,\n",
       "         0.47218645,  3.350997  ,  1.9592443 ,  1.5252193 ,  0.6469809 ],\n",
       "       dtype=float32),\n",
       " '은': array([ 1.3530395 ,  1.152476  , -0.00490719,  1.1032438 , -2.1967862 ,\n",
       "        -2.1037016 , -0.16869897,  1.099882  ,  0.39877808, -0.33955395],\n",
       "       dtype=float32),\n",
       " '이잉걸': array([ 0.9413003 ,  1.8734531 , -0.9507375 ,  0.3802702 , -3.1289344 ,\n",
       "         0.20544308,  1.2632269 , -0.1426189 ,  0.6573719 ,  1.3963253 ],\n",
       "       dtype=float32),\n",
       " '학생': array([ 0.22291288,  0.29848224, -1.6472098 ,  0.3392419 , -1.988097  ,\n",
       "        -1.1445596 , -1.7179128 ,  0.72005886,  2.7951117 ,  0.21058607],\n",
       "       dtype=float32),\n",
       " '회장': array([ 0.55242383,  1.8319519 , -1.798766  ,  1.9305265 , -2.5245993 ,\n",
       "        -0.5049012 ,  0.61437875,  1.3248427 ,  1.2709328 ,  2.480298  ],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector = dict(zip(words, w2v_result))\n",
    "word_vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
